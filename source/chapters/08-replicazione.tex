\chapter{Dinamiche di Replicazione} % (fold)
\label{cha:dinamiche_di_replicazione}
Le dinamiche di replicazione sono una classe di sistemi dinamici studiati nel contesto della teoria dei giochi evoluzionistici, una disciplina nata da J. Maynard Smith con l’obiettivo di modellare l’evoluzione del comportamento animale utilizzando i principi e i mezzi della teoria dei giochi.\\

Si consideri una \emph{popolazione grande}, idealmente infinita, appartenente alla stessa specie che compete per un particolare insieme di \emph{risorse limitate}, come cibo, territorio, etc... Si suppone inoltre che ciascun individuo sia pre-programmato ad una particolare strategia pura. È possibile modellare questo tipo di conflitto come un gioco in cui iterativamente vengono estratti a caso due giocatori dalla popolazione e fatti competere.\\

La vittoria del gioco contribuisce alla sopravvivenza della specie, in quanto il payoff in questo contesto rappresenta il successo riproduttivo. La riproduzione avviene in modo asessuato per cui, a meno di mutazioni, ogni nuovo nascituro sarà un clone del genitore, ovvero, nel nostro caso, programmato alla sua stessa strategia pura. Nell’evolversi della dinamica avremo che, per il \textbf{principio di selezione naturale}, gli individui più forti, che hanno cioè adottato una strategia migliore, tenderanno a dominare gli individui più deboli, con la conseguente estinzione di questi ultimi.

\newpage

\section{Teoria dei Giochi Evoluzionistici} % (fold)
\label{sec:teoria_dei_giochi_evoluzionistici}
Si consideri una grande popolazione di individui programmati a strategie pure $i \in \{1, \dots, n\}$.\\

Sia $\mathbf{x}(t) \in \Delta$ il vettore che rappresenta lo stato della popolazione al tempo $t$ dove $x_i(t)$ è la percentuale di popolazione programmata alla strategia pura $i$. Sia $A=a_{ij}$ la matrice $n \times n$ di payoff dove $a_{ij}$ rappresenta il payoff che si ottiene giocando la strategia $i$ contro la strategia $j$ di un altro individuo. Se la popolazione si trova allo stato $x$ il payoff atteso di un individuo che gioca la strategia $i$ è dato da:
\begin{align}
	\pi_i (x) = \sum_{j=1}^n a_{ij} x_j = (Ax)_i
\end{align}

mentre il payoff medio sull'intera popolazione è:
\begin{align}
	\pi (x) = \sum_{i=1}^n x_i \pi_i(x) = (x^T A x)
\end{align}

Nella teoria dei giochi evoluzionistici si fa l’assunzione che la popolazione giochi iterativamente generazione dopo generazione e che l’azione della selezione naturale porti alla sopravvivenza delle strategie più forti, od in questo caso di quelle con payoff maggiore.\\

Dinamiche di questo tipo possono essere descritte da un insieme di equazioni differenziali rispetto al tempo del tipo:
\begin{align*}
    \dot{x}_i = g_i(\mathbf{x}) x_i \qquad \forall{i}
\end{align*}
dove $g_i(\mathbf{x})$ indica il fattore di replicazione delle strategie pure $i$ quando la popolazione si trova nello stato $\mathbf{x}$. \\

Un punto $\mathbf{x}$ è detto \textbf{stazionario} se $\dot{x}_i = 0, \forall i$. Un punto stazionario è \textbf{asintoticamente stabile} se qualunque traiettoria, che inizia sufficientemente vicino ad $\mathbf{x}$, converge a $\mathbf{x}$ quando $t \rightarrow \infty$.\\

Nel caso in cui il tempo sia discreto, l'equazione di replicazione assume la seguente forma:
\begin{align}
	x_i(t + 1) = \frac{x_i(t) \pi_i(t)}{\displaystyle\sum_{j=1}^n x_j(t) \pi_j(t)}
\end{align}
mentre nel caso in cui il tempo scorra in maniera continua:
\begin{align}
	\frac{d}{dt} x_i(t) = x_i(t) \left( \underbrace{\pi_i(t)}_\textrm{payoff strategia pura $i$} - \underbrace{\sum_{j=1}^n x_j(t) \pi_j(t)}_\textrm{payoff medio della popolazione} \right)
\end{align}

I punti stazionari di questa dinamica si ottengono se e solo se tutte le strategie nel supporto di $\mathbf{x}$ ottengono lo stesso payoff. 

% section teoria_dei_giochi_evoluzionistici (end)





\section{Equilibri Evolutionary Stable} % (fold)
\label{sec:equilibri_evolutionary_stable}
Si suppone ora che un piccolo gruppo di mutanti (o invasori) appaia in una grande popolazione di individui programmata a giocare la stessa strategia $\mathbf{x} \in \Delta$ (\emph{strategia incombente}).\\

Si suppone che gli invasori siano programmati a giocare una strategia $\mathbf{y} \in \Delta$ (\emph{strategia mutante}). Sia $\epsilon$ la frazione di mutanti con $\epsilon \in (0, 1)$. Coppie di individui sono scelti casualmente a giocare in base ad una distribuzione di probabilità uniforme. \\

Se un individuo viene scelto allora la probabilità che questo si scontri con un mutante è $\epsilon$ mentre la probabilità che l’avversario non lo sia è $1 - \epsilon$. \\

Il payoff che un individuo ottiene in questa popolazione è lo stesso che otterrebbe se si scontrasse con un individuo programmato a giocare la strategia:
\begin{align*}
    \mathbf{w} = \epsilon \mathbf{y} + (1 - \epsilon) \mathbf{x} \in \Delta
\end{align*}
Quindi un individuo della popolazione originale otterrebbe un payoff pari a $u(\mathbf{x}, \mathbf{w})$, mentre un mutante otterrebbe un payoff pari a $u(\mathbf{y}, \mathbf{w})$. Da un punto di vista biologico ci si aspetta che l’evoluzione forzi una selezione contro gli individui mutanti solo se la strategia mutante ottiene un payoff inferiore rispetto a quella incombente. In termini matematici:
\begin{align}
    \underbrace{u(\mathbf{x}, \mathbf{w})}_\textrm{incombente} > \underbrace{u(\mathbf{y}, \mathbf{w})}_\textrm{mutante}\label{eq:es}
\end{align}

In questo contesto si introduce il seguente teorema:
\begin{thm}[Evolutionary Stable Strategy]\label{thm:ess}
    Una strategia $\mathbf{x} \in \Delta$ è detta \emph{evolutionary stable} (ESS) se per ogni $\mathbf{y} \in \Delta - \{ \mathbf{x}\}$ esiste un $\delta \in (0, 1)$, tale per cui per ogni $\epsilon \in (0, \delta)$ la disuguaglianza \eqref{eq:es} è vera. Si definisce $\Delta^{ESS}$ l'insieme delle strategie ESS. Formalmente è possibile definire l'insieme delle strategie ESS come:
    \begin{align*}
        \Delta^{ESS} = \left\{\mathbf{x} \in \Delta^{NE} : u(\mathbf{y}, \mathbf{y}) < u(\mathbf{x}, \mathbf{y}), \forall \mathbf{y} \in \beta^*(\mathbf{x}), \mathbf{y} \neq \mathbf{x} \right\}
    \end{align*}
    O in modo del tutto equivalente $x \in \Delta^{ESS}$ sse
    \begin{enumerate}
        \item $u(\mathbf{y}, \mathbf{x}) \leq u(\mathbf{x}, \mathbf{x})$ \quad $\forall y \in \Delta$ (Equilibrio di Nash);
        \item $u(\mathbf{y}, \mathbf{x}) = u(\mathbf{x},\mathbf{x}) \implies u(\mathbf{y},\mathbf{y}) < u(\mathbf{x},\mathbf{y})$ \quad $\forall \mathbf{y} \in \Delta - \{\mathbf{x}\}$ (Condizione di stabilità).
    \end{enumerate}
\end{thm}

Ciò significa che una strategia evolutionary stable non può essere invasa da un altra strategia.
Si derivano ora alcuni importanti risultati riguardanti gli stati asintoticamente stabili nelle dinamiche di replicazione.

\begin{prop}
    Se $\mathbf{x} \in \Delta$ è asintoticamente stabile, allora $\mathbf{x} \in \Delta^{NE}$
\end{prop}

Questo risultato garantisce che se con le dinamiche di replicazione si giunge in uno stato $\mathbf{x}$ e questo rimane stabile anche se sottoposto a piccole perturbazioni, allora $\mathbf{x}$ è un equilibrio di Nash. 

\newpage

Tuttavia il fatto che il contrario non valga significa che esistono giochi privi di stati asintoticamente stabili, per i quali quindi è più problematica la ricerca di un equilibrio di Nash.

\begin{prop}
    Se $\mathbf{x} \in \Delta^{ESS}$ allora $\mathbf{x}$ è asintoticamente stabile.
\end{prop}

Gli equilibri ESS sono quindi particolarmente interessanti perché godono della stabilità asintotica, ma anche in questo caso, non è possibile affermare se esista o meno uno corrispondenza uno ad uno tra equilibri ESS e stati asintoticamente stabili. In altre parole, a differenza degli equilibri di Nash, l'esistenza di equilibri ESS non è garantita.\\

Si consideri come esempio il gioco “Carta, Forbice, Sasso”. La matrice di payoff è data da:

\begin{table}[h!]
	\centering
	\begin{tabular}{ c c | c | c | c |}
        \cline{3-5}
		& & \multicolumn{3}{c |}{\textbf{Giocatore 2}} \\
        \cline{3-5}
		&  &  Sasso  & Forbice & Carta \\
		\hline
		\multicolumn{1}{| c |}{\multirow{3}{*}{\textbf{Giocatore 1}}} & Sasso & 0,0 & 1,-1 & -1, 1 \\
        \cline{2-5}
        \multicolumn{1}{| c |}{}  & Forbice & -1,1 & 0,0 & 1,-1\\
        \cline{2-5}
        \multicolumn{1}{| c |}{}  & Carta & 1,-1 & -1,1 & 0,0 \\
        \hline
	\end{tabular}
	\caption{Matrice di payoff del gioco Carta, Forbice, Sasso}
\end{table}
Si nota che il gioco Carta, Forbici e Sasso è un gioco a somma zero: in qualunque stato del gioco, la somma delle utilità dei giocatori è zero. Il gioco Carta, Forbici e Sasso è anche finito: l'insieme $N$ dei giocatori ha cardinalità finita, così come gli insiemi di strategie $S_1, \dots, S_n$.\\

Il gioco non ammette equilibri di Nash basati su strategie pure. Tuttavia, se si definisce $\mathbf{x}=(1/3, 1/3, 1/3)^T$ come distribuzione di probabilità di una strategia mista, allora $(\mathbf{x}, \mathbf{x})$ è un equilibrio di Nash misto. Infatti è possibile verificare che se il giocatore 2 usa la distribuzione di probabilità $\mathbf{x}$, il giocatore 1 non ha alcun incentivo nel giocare una strategia che sia diversa da $\mathbf{x}$. \\

È possibile dimostrare che il gioco non ammette equilibri ESS. Si consideri una strategia “mutante” $\mathbf{y} = (1, 0, 0)^T$. Si nota che $u(\mathbf{y},\mathbf{y}) = 0$ e $u(\mathbf{x}, \mathbf{y}) = 0 + 1 - 1 = 0$ per cui $u(\mathbf{y}, \mathbf{y}) = u(\mathbf{x}, \mathbf{y})$ e quindi $\Delta^{ESS} = \emptyset$ in quanto non vale la seconda condizione nel teorema \ref{thm:ess}.
% section equilibri_evolutionary_stable (end)

\subsection{Giochi doppiamente simmetrici ed equilibri ESS} % (fold)
\label{sub:giochi_doppiamente_simmetrici_ed_equilibri_ess}

Un gioco $G= (I, \Theta, u)$ a due giocatori è detto doppiamente simmetrico se oltre ad essere simmetrico $u(\mathbf{x}, \mathbf{y}) = u(\mathbf{y}, \mathbf{x}) \quad \forall(\mathbf{x}, \mathbf{y}) \in \Theta$.\\

Losrt e Akin (1983) mostrarono che il teorema fondamentale di selezione naturale\footnote{Il teorema fondamentale di selezione naturale afferma che se c'è selezione naturale, il payoff medio di una popolazione tende ad aumentare} si applica a tutti i giochi doppiamente simmetrici. Essi mostrarono che, con le dinamiche di replicazione, se $A = A^T$ il fitness (payoff) medio della popolazione  $f(\mathbf{x}) = \mathbf{x}^T A \mathbf{x}$  cresce lungo tutti i cammini di soluzione non stazionari; formalmente mostrarono che:
\begin{align*}
    \frac{d}{dt} f(\mathbf{x}(t)) \geq 0 \qquad \forall t \geq 0 \tag{Caso continuo}
\end{align*}
\begin{align*}
	f(\mathbf{x}(t + 1)) \geq f(\mathbf{x}(t)) \tag{Caso discreto}
\end{align*}
con l’uguaglianza sse $\mathbf{x}$ è un punto stazionario.\\
Come conseguenza di questi risultati si ottiene la seguente caratterizzazione degli stati asintoticamente stabili per i giochi doppiamente simmetrici.

\begin{prop}
    Per un qualunque gioco doppiamente simmetrico le seguenti affermazioni sono equivalenti:
    \begin{enumerate}
        \item $\mathbf{x} \in \Delta^{ESS}$;
        \item $\mathbf{x} \in \Delta$ è un massimo locale di $u(\mathbf{x}, \mathbf{x})$ in $\Delta$;
        \item $\mathbf{x} \in \Delta$ è asintoticamente stabile nelle dinamiche di replicazione.
    \end{enumerate}
\end{prop}

% subsection sub:giochi_doppiamente_simmetrici_ed_equilibri_ess (end)
% chapter dinamiche_di_replicazione (end)

