%!TEX TS-options = --shell-escape

\chapter{Reti di Hopfield} % (fold)
\label{cha:reti_di_hopfield}
Si passa ora allo studio delle reti neurali viste come sistemi dinamici non lineari, con particolare attenzione al problema della loro stabilità \textbf{(neurodinamica)}. Un modo implicito per introdurre in una rete neurale la variabile tempo è mediante l’utilizzo di reti con feedback o ricorrenti.

\section{Sistemi dinamici} % (fold)
\label{sec:sistemi_dinamici}
Un modello matematico per descrivere le dinamiche di un sistema non lineare è lo spazio degli stati. Con questo modello si pensa in termini di variabili di stato i cui valori ad un certo istante temporale sono considerati sufficienti a predire la futura evoluzione del sistema.\\

Sia $\bar{x}(t) = x_1(t), \dots, x_N(t)$ il \textbf{vettore di stato}, un vettore contenente le variabili di stato di un sistema dinamico non lineare, in cui la variabile indipendente è il tempo $t$ e $N$ è l'ordine del sistema. È possibile allora descrivere un largo numero di sistemi dinamici non lineari mediante un sistema di equazioni differenziali di primo ordine chiamate equazioni dello spazio degli stati ed aventi la seguente forma:
\begin{align}
	\frac{d}{dt} \bar{x}(t) = F(\bar{x}(t))\label{eq:stati}
\end{align}
dove $F(\bar{x})$ è una funzione vettore che se applicata ad un vettore $\bar{x}$ ritorna un vettore che ha come j-esima componente $F_j(x_j)$ con $F_j$ una qualche funzione; si può pensare a quest'ultimo come come ad un \textbf{vettore di velocità}. Un sistema in cui la funzione vettore $F$ non dipende esplicitamente dal tempo è detto \textbf{autonomo}. In questo capitolo saranno trattati solo sistemi dinamici autonomi.\\

L'Equazione~\eqref{eq:stati} può essere vista come un descrittore del movimento di un punto nello spazio degli stati N-dimensionale; questo punto non è altro che lo stato del sistema osservato ad un certo istante $t$. Con lo scorrere del tempo il punto $t$ descrive una curva nello spazio degli stati detta \textbf{traiettoria} o orbita del sistema.

\newpage

La velocità istantanea della traiettoria è rappresentata da un vettore tangente; possiamo quindi derivare un vettore di velocità per ogni punto della traiettoria.
La famiglia delle traiettorie, per differenti condizioni iniziali, è chiamato \emph{ritratto degli stati} del sistema e comprende tutti quei punti per cui $F(\bar{x})$ è definita; nel caso di sistemi autonomi per ogni punto dello spazio esiste una sola traiettoria che vi passa.

\begin{figure}[h!]
	\centering
	\begin{tikzpicture}
	    \draw[very thin,color=gray!20] (0,0) grid (5,5);
	    \draw[->] (0,0) -- (0,5) node[right] {$x_1$};
	    \draw[->] (0,0) -- (5,0) node[above] {$x_2$};

	    \draw[thick, color=red] plot [smooth, tension=1] coordinates{(3, 5) (2.4, 3) (3.8, 3.5)};
	    \draw[thick, color=blue] plot [smooth, tension=1] coordinates{(2, 5) (2, 2.5) (4, 3.3)};
	    \draw[thick, color=orange] plot [smooth, tension=1] coordinates{(1, 5) (2, 1.5) (4.2, 3.2)};
	\end{tikzpicture}
	\caption{Un ritratto degli stati bidimensionale di un sistema dinamico.}
\end{figure}

\subsection{Condizione di Lipschitz} % (fold)
\label{sub:condizione_di_lischitz}
Affinchè l’equazione dello spazio degli stati abbia soluzione e questa sia unica è necessario imporre alcune restrizioni sul vettore $F(\bar{x})$. Condizione sufficiente affinchè vi sia soluzione è che $F(x)$ sia continua in tutti i suoi argomenti; tuttavia questa condizione non garantisce l’unicità della soluzione. Serve una restrizione più forte conosciuta come condizione di Lipschitz. Una funzione:
\begin{align*}
    \mathbf{f}: \Omega \subseteq \mathbb{R}^n \rightarrow \mathbb{R}^m
\end{align*}
si dice “lipschitziana” su $\Omega$ se:
\begin{align*}
    \exists K \ge 0 
\end{align*}
tale che 
\begin{align*}
    \left \| \mathbf{f}(\mathbf{x}) - \mathbf{f}(\mathbf{y}) \right \| \le K \left \| \mathbf{x} - \mathbf{y} \right \| \qquad \forall \mathbf{x}, \mathbf{y} \in \Omega 
\end{align*}

\newpage

\begin{figure}[h!]
    \centering
    \begin{tikzpicture}[domain=-2:2]
        \begin{axis}[restrict y to domain=-2:2, grid]
            \addplot[blue,smooth,thick] function{sin(x) * cos(4 * x)} node[above=1cm] {\tiny$\sin(x)\cos(4x)$};
            \addplot[green, thick] function{- 4 * x} node[below] {\tiny$-4x$};
            \addplot[green, thick] function{4 * x} node[above] {\tiny$4x$};
        \end{axis}
    \end{tikzpicture}
    \caption{Interpretazione grafica della Condizione di Lipschitz: la funzione $f=\sin(x)\cos(4x)$ è lipschitziana con $K=4$. Ciò significa che se si considera un qualunque punto lungo la funzione e si tracciano le rette di coefficienti angolari 4 e -4, allora $f$ non sarà mai confinata tra le due rette.}
\end{figure}

% subsection condizione_di_lischitz (end)

\subsection{Stati di equilibrio} % (fold)
\label{sub:stabilità_degli_stati_di_equilibrio}
Intuitivamente un punto/stato di equilibrio stabile è un punto che non risente delle piccole perturbazioni: se ci si sposta poco da un punto stabile il sistema continuerà a rimanere anche in futuro nelle vicinanze di quel punto. L'esempio più semplice è quello di una pallina disposta esattamente nel fondo di una valle, se la spostiamo di poco dal fondo può rotolare in basso ed oscillare ma non aumenta la sua distanza dal punto di equilibrio.\\

Una palla nel fondo di una valle è in una posizione di equilibrio stabile, una in cima ad una collina è in posizione di equilibrio instabile. Viceversa un punto di equilibrio instabile è tale per cui basta una perturbazione arbitrariamente piccola dall'equilibrio per far allontanare significativamente il sistema dalla posizione iniziale. Un esempio è una pallina disposta sulla cima di una collina.\\

Un vettore costante $\bar{x}\in M$ è detto stato di equilibrio (stazionario) se è soddisfatta la seguente condizione:
\begin{align*}
    \mathbf{F}(\bar{x}) = 0
\end{align*}
dove 0 è il vettore nullo. Il vettore velocità si annulla nel punto di equilibrio e quindi $\mathbf{x}(t) = x$ è una soluzione dell'equazione dello spazio degli stati. Lo stato di equilibrio è anche detto punto singolare e la traiettoria degenera nel punto stesso. Si enunciano ora una serie di definizioni sulla stabilità degli stati di equilibrio.

\begin{mydef}
    Lo stato di equilibrio $x$ è detto \textbf{uniformemente stabile} se per ogni $\bar{x}$ positivo, esiste un $\epsilon$ positivo tale che la condizione:
    \begin{align*}
        \left|\mathbf{x}(0) - \bar{x} \right| < \delta
    \end{align*}
    implica
    \begin{align*}
        \left|\mathbf{x}(t) - \bar{x} \right| < \epsilon
    \end{align*}
    per ogni $t > 0$.
\end{mydef}

Questa definizione afferma che una traiettoria del sistema può essere fatta stare in un piccolo
intorno dello stato di equilibrio $\bar{x}$ se il suo stato iniziale è vicino a $\bar{x}$.

\begin{mydef}
    Lo stato di equilibrio $x$ è detto \textbf{convergente} se esiste un $\delta$ positivo tale che la
    condizione:
    \begin{align*}
        \left|\mathbf{x}(0) - \bar{x} \right| < \delta
    \end{align*}
    implica che:
    \begin{align*}
        \lim_{t \rightarrow \infty} \mathbf{x}(t) = \bar{x}
    \end{align*}
\end{mydef}
Questa seconda definizione afferma che se lo stato iniziale di una traiettoria è adeguatamente vicino allo stato di equilibrio $x$, allora la traiettoria descritta dal vettore di stato $x(t)$ convergerà a $x$ all'aumentare del tempo.
% subsection stabilità_degli_stati_di_equilibrio (end)
\begin{mydef}
    Lo stato di equilibrio $\bar{x}$ è detto \textbf{asintoticamente stabile} se è stabile e convergente.
\end{mydef}
\begin{mydef}
    Lo stato di equilibrio $x$ è detto \textbf{globalmente asintoticamente stabile} se è stabile e se
    tutte le traiettorie del sistema convergono a $x$ per $t$ che tende ad infinito.
\end{mydef}

\newpage


\subsection{Teorema di Lyapunov} % (fold)
\label{sub:teorema_di_lyapunov}
Si enunciano ora i due teoremi di Lyapunov che forniscono condizioni sufficienti per l'esistenza di un punto stazionario.

\begin{thm}[Primo teorema di Lyapunov]
    Lo stato di equilibrio $\bar{x}$ è stabile se in un piccolo intorno di $\bar{x}$ esiste una funzione definita positiva $V(x)$ tale che la sua derivata rispetto al tempo è minore o uguale a 0 in quella regione.
\end{thm}

\begin{thm}[Secondo teorema di Lyapunov]
     Lo stato di equilibrio $\bar{x}$ è asintoticamente stabile se in un piccolo intorno di $\bar{x}$ esiste una funzione definita positiva $V(x)$ tale che la sua derivata rispetto al tempo sia strettamente minore di 0 in quella regione.
\end{thm}

Una funzione scalare $V(x)$ che soddisfa queste proprietà è detta \textbf{funzione di Lyapunov} per lo stato di equilibrio $\bar{x}$.
La funzione $V(x)$ è definita positiva nello spazio degli stati $L$, se $\forall x \in L$, soddisfa le seguenti proprietà:
\begin{enumerate}
    \item la funzione $V(x)$ ha derivate parziali rispetto agli elementi di $\mathbf{x}$ continue;
    \item $V(\bar{x})=0$;
    \item $V(x)>0$ se $\mathbf{x} \neq \bar{x}$.
\end{enumerate}

Supposta $V(x)$ una funzione di Lyapunov, lo stato di equilibrio $\bar{x}$ è stabile se:
\begin{align*}
    \frac{d}{dt} \cdot V(\mathbf{x}) \leq 0, \qquad \text{se } \left|x - \bar{x} \right| \leq \epsilon
\end{align*}
dove $\epsilon$ è un numero positivo. Lo stato di equilibrio è asintoticamente stabile se:
\begin{align*}
    \frac{d}{dt} \cdot V(\mathbf{x}) < 0, \qquad \text{se } \left|x - \bar{x} \right| \leq \epsilon
\end{align*}

Il criterio è una generalizzazione del fatto, ben noto nella fisica, che un sistema meccanico, se lasciato libero di evolvere, tende a portarsi in una configurazione dove la sua energia potenziale è minima. La funzione di Lyapunov può quindi essere interpretata come una funzione di energia potenziale generalizzata. Il criterio dice che uno stato di equilibrio è stabile se:
\begin{enumerate}
    \item è minimo per una certa funzione di energia generalizzata (cioè se esiste una funzione di Lyapunov definita positiva);
    \item se il sistema tende a portarsi verso la configurazione di minimo della funzione di Lyapunov (cioè se la derivata della funzione di Lyapunov è semidefinita negativa).
\end{enumerate}
Il criterio è una \textbf{condizione sufficiente ma non necessaria}. Non è detto in generale che l'origine non sia stabile se non esiste una funzione di Lyapunov definita in un intorno dell'origine. Inoltre non esiste un algoritmo per trovare la funzione di Lyapunov relativa a un sistema, ma si deve cercare per tentativi, basandosi sul tipo di funzione di stato e su considerazioni puramente fisiche.

% subsection teorema_di_lyapunov (end)


% section sistemi_dinamici (end)

\section{Modello di Hopfield: caso discreto} % (fold)
\label{sec:modello_di_hopfield_caso_discreto}

Le reti ricorrenti con unità non lineari sono generalmente difficili da analizzare.  Possono comportarsi in modi differenti: convergere a uno stato stabile, oscillare o seguire \emph{traiettorie caotiche} il cui andamento non è prevedibile.\\

Tuttavia, il fisico americano \emph{John Hopfield} (e altri gruppi) si accorsero che se le connessioni sono \textbf{simmetriche} esiste una \emph{funzione di energia globale}.\\

Le reti di Hopfield sono dunque:
\begin{itemize}
    \item \textbf{reti ricorrenti ad uno strato} in cui ogni neurone è connesso a tutti gli altri (sono assenti
connessioni con se stesso), quindi $w_{ii}=0$;
    \item \textbf{simmetriche}: perché hanno la matrice dei pesi sinaptici simmetrica, ovvero $W=W^T$;
    \item \textbf{non lineari}: ogni neurone ha una funzione di attivazione non lineare invertibile.
\end{itemize}

\begin{figure}[h!]
	\centering
	\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=4cm, semithick]
		\tikzstyle{every state}=[align=center, fill=blue!20,draw=blue]
		
		% Draw nodes.
		\node[state] (1) {$1$};
		\node[state, right of=1] (2) {$2$};
		\node[state, right of=2] (N) {$N$};
        
        % Draw edges
        \path 
        (1) edge[bend left, below] node {$w_{12}$} (2)
        (1) edge[bend left] node {$w_{1N}$} (N)
        (2) edge[bend left] (1)
        (2) edge[bend left] (N)
        (N) edge[bend left] (1)
        (N) edge[bend left] (2)
        (2) edge[dotted, -] (N);
        
	\end{tikzpicture}
    \caption{Una rete ricorrente.}
\end{figure}

\newpage

Per quanto riguarda l'aggiornamento di un neurone si possono scegliere tre strade diverse:
\begin{enumerate}
    \item \textbf{aggiornamento asincrono}: in cui si aggiorna un neurone alla volta;
    \item \textbf{aggiornamento sincrono}: tutti i neuroni vengono aggiornati allo stesso istante;
    \item \textbf{aggiornamento continuo}: in cui tutti i neuroni si aggiornano continuamente.
\end{enumerate}

In questa sezione saranno trattate le reti di Hopfield nel caso discreto con aggiornamento asincrono, mentre nella prossima si studia il caso continuo con aggiornamento continuo.\\

Nel caso discreto si adotta il modello di McCulloch e Pitts, in cui l'input al neurone $i$ è influenzato da un fattore esterno:
\begin{align}
    H_i = \underbrace{\sum_{j \neq i} w_{ij} V_j}_\textrm{modello M\&P} + \underbrace{I_i}_\textrm{input esterno}
\end{align}
E l'output di ogni neurone è così definito:
\begin{align}
    V_i =
    \begin{cases}
        +1, &\text{ se } H_i \geq 0\\
        -1, &\text{ se } H_i < 0
    \end{cases}\label{eq:learningrule}
\end{align}
L'aggiornamento dei neuroni è un processo casuale. Per selezionare il neurone da aggiornare si può procedere in due modi:
\begin{enumerate}
    \item ad ogni istante temporale si sceglie a caso l'unità $i$ da aggiornare (utile nelle simulazioni);
    \item Ogni unità si aggiorna indipendentemente con probabilità costante ad ogni istante.
\end{enumerate}

\newpage

A differenza delle reti feed-forward quelle di Hopfield sono sistemi dinamici. La rete parte da uno stato iniziale
\begin{align*}
    V(0) = (V_1(0), \dots, V_n(0))^T
\end{align*}

 e si evolve lungo una traiettoria fino a raggiungere un punto fisso in cui $V(t+1) = V(t)$ (convergenza).
 \begin{figure}[h!]
     \centering
     \begin{tikzpicture}
         \node[point] (0) at (-4, 0) {};
         \node[point] (1) at (-2, 2) {};
         \node[point] (2) at (0, -0.4) {};
         \node[point] (3) at (2, 1) {};
         \node[point] (4) at (4, 0) {};
         \node[point] (5) at (6, -0.5) {};
         \node[point] (6) at (8, 0.5) {};
         
         \foreach \x / \y in {0/1,1/2,2/3,3/4,4/5,5/6}
             \path (\x) edge[->] (\y);
         
         \foreach \x in {0,...,6}
             \node[above=2mm of \x] {\small$V(\x)$};
         
     \end{tikzpicture}
     \caption{Traiettoria di una rete di Hopfield}
 \end{figure}

\subsection{La funzione energia} % (fold)
\label{sub:funzione_energia}
Si procede ora allo studio del comportamento di una rete di Hopfield; fino ad ora infatti non abbiamo dimostrato se la rete converge oppure produce cicli. Il sistema è governato da una funzione di energia $E$. L'energia globale è la somma di una serie di contributi locali. Ogni contributo dipende da \textbf{una} connessione $w_{ij}$ e dagli stati binari dei \textbf{due} neuroni $V_i V_j$. La funzione energia è dunque così definita:
\begin{align}
    E = - \frac{1}{2} \sum_{i=1}^n \sum_{\substack{j=1 \\ j \neq i}}^n w_{ij} V_i V_j - \sum_{i=1}^n I_i V_i\label{eq:energy}
\end{align}
Dove $I$ è il fattore esterno (termine bias) e coinvolge lo stato di un'unità individualmente. Questa funzione permette ad ogni unità di calcolare \textbf{localmente} come il suo cambio di stato influenza l'energia globale. In termini matematici la differenza di energia è definita nel seguente modo:
\begin{align}
    \emph{Energy gap }\Delta E = E(t + 1) - E(t)
\end{align}
 % subsection funzione_energia (end) 

\newpage

\subsection{Teorema di Hopfield nel caso discreto} % (fold)
\label{sub:teorema_di_hopfield_nel_caso_discreto}
Si enuncia ora una condizione sufficiente alla convergenza del sistema.
\begin{thm}[Terorema di Hopfield - Caso discreto]
    Se la matrice dei pesi di una rete di Hopfield è:
    \begin{enumerate}
        \item simmetrica: $W=W^T$;
        \item gli elementi lungo la diagonale di $W$ sono nulli: $diag(W) = 0$.
    \end{enumerate}
    Allora la funzione di energia:
    \begin{align*}
    E = - \frac{1}{2} \sum_{i=1}^n \sum_{\substack{j=1 \\ j \neq i}}^n w_{ij} V_i V_j - \sum_{i=1}^n I_i V_i
    \end{align*}
    è una funzione di Lyapunov per il sistema. E quindi:
    \begin{align*}
        \Delta E = E(t+1) - E(t) < 0
    \end{align*}
    dove $\Delta E = 0$ solo quando il sistema ha raggiunto un punto stazionario.
\end{thm}

\begin{proof}[Dimostrazione:]
    Assumendo che i neuroni si aggiornano in modo asincrono, supponiamo che il neurone $h$ cambi il proprio stato. La differenza di energia è data da:
    \begin{align*}
            \Delta E &= - \frac{1}{2} \sum_{i=1}^n \sum_{\substack{j=1 \\ j \neq i}}^n w_{ij} V_i(t + 1) V_j(t + 1) - \sum_{i=1}^n I_i V_i(t + 1) \\
            & \quad + \frac{1}{2} \sum_{i=1}^n \sum_{\substack{j=1 \\ j \neq i}}^n w_{ij} V_i(t) V_j(t) + \sum_{i=1}^n I_i V_i(t) \\
            &= \underbrace{- \frac{1}{2} \sum_{i=1}^n \sum_{\substack{j=1 \\ j \neq i}}^n w_{ij} \cdot [V_i(t + 1) V_j(t + 1) - V_i(t) V_j(t)]}_\textbf{$A$} \\
            & \underbrace{- \sum_{i=1}^n I_i \cdot [V_i(t + 1) - V_i(t)]}_\textbf{$B$}
    \end{align*}
    
    \newpage
    
    Si consideri il secondo termine $B$:
    \begin{align*}
        B = - \sum_{i=1}^n I_i \Delta V_i
    \end{align*}
    ora dal momento che $h$ è l'unico stato che è cambiato abbiamo che
    \begin{align*}
        B = - I_h \Delta V_h
    \end{align*}
    in quanto tutti gli altri $\Delta$ sono uguali a 0.\\
    
    Si passa ora al primo termine $A$. Si porta fuori dalla sommatoria il neurone $h$:
    \begin{align*}
        A &= \underbrace{- \frac{1}{2} \sum_{i \neq h} \sum_{j \neq i} w_{ij} \cdot [V_i(t + 1) V_j(t + 1) - V_i(t) V_j(t)]}_\textrm{$A_1$} \\
        & \underbrace{- \frac{1}{2} \sum_{j \neq h} w_{hj} \cdot [V_h(t + 1) V_j(t + 1) - V_h(t) V_j(t)]}_\textrm{$A_2$}
    \end{align*}
    Dal momento che solo il neurone $h$ cambia stato allora $V_i(t) = V_i(t + 1)$ per $i \neq h$ quindi $A_1$ può essere riscritto nel seguente modo:
    \begin{align*}
        A_1 &= - \frac{1}{2} \sum_{i \neq h} \sum_{j \neq i} w_{ij} \cdot [V_i(t + 1) V_j(t + 1) - V_i(t) V_j(t)] \\
        &= - \frac{1}{2} \sum_{i \neq h} \sum_{j \neq i} w_{ij} \cdot V_i(t) [V_j(t + 1) - V_j(t)] \\
        &\text{A questo punto $\Delta V_j \neq 0$ solo quando $j = h$ quindi $\Delta V_j = \Delta V_h$} \\
        &= - \frac{1}{2} \sum_{i \neq h} w_{ih} V_i(t) \Delta V_h
    \end{align*}
    Per quanto riguarda $A_2$ il procedimento è lo stesso:
    \begin{align*}
        A_2 &= - \frac{1}{2} \sum_{j \neq h} w_{hj} \cdot [V_h(t + 1) V_j(t + 1) - V_h(t) V_j(t)] \\
        &= - \frac{1}{2} \sum_{i \neq h} w_{hi} V_i(t) \Delta V_h
    \end{align*}
    Siccome la matrice dei pesi è simmetrica $W = W^T$ allora $w_{ih} = w_{hi}$ e quindi:
    \begin{align*}
        A = A_1 + A_2 = - \Delta V_h \sum_{i \neq h} w_{ih} V_i(t)
    \end{align*}
	
	\newpage
	
    In questo modo si ottiene:
    \begin{align*}
        \Delta E &= - \Delta V_h \sum_{i \neq h} w_{ih} V_i(t)  - I_h \Delta V_h \\
        &= - \Delta V_h \underbrace{\left[\sum_{i \neq h} w_{ih} V_i(t) + I_h \right]}_\textrm{input di $h$ al tempo t} \\
        &= - \Delta V_h \cdot H_h
    \end{align*}
A questo punto è necessario dimostrare che il prodotto $\Delta V_h \cdot H_h$ è sempre positivo in modo tale da provare la tesi, ovvero che $\Delta E \leq 0$. Per la regola di apprendimento \eqref{eq:learningrule}:
\begin{enumerate}
    \item se $V_h > 0 \Leftrightarrow H_h \geq 0$
    \item se $V_h < 0 \Leftrightarrow H_h < 0$
\end{enumerate}
Dunque il prodotto è sempre positivo C.V.D.
\end{proof}
% subsection teorema_di_hopfield (end)

% section modello_di_hopfield_caso_discreto (end)

\newpage

\section{Regola di Hebb}
Nei computer se si vuole accedere ad una certa informazione si utilizza il suo preciso indirizzo di memoria. Questo tipo di memoria è definita \emph{byte-addressable memory}. Nel cervello umano, invece, la memoria è indirizzata in base al contenuto, \emph{content-addressable memory}. Ad esempio pensare alla parola “volpe” potrebbe automaticamente attivare memorie relative ad altri animali simili, alla caccia, oppure al concetto di furbizia.\\

In questo contesto, è stata introdotta la \emph{regola di Hebb} per descrivere questo meccanismo di accesso alle informazioni. L'apprendimento Hebbiano si basa sul semplice principio che se due neuroni si attivano contemporaneamente, la loro interconnessione deve essere rafforzata. In dettaglio il postulato di Hebb afferma che:\\

\emph{Quando un assone di un neurone A è abbastanza vicino da eccitare un neurone B e questo, in modo ripetitivo e persistente, gli invia un potenziale di azione, inizia un processo di crescita in uno o entrambi i neuroni tali da incrementare l'efficienza di A.}\\

In termini matematici la memoria è rappresentata da un insieme di $p$ patterns $x^\mu$, con $\mu=1,\dots,p$. Quando viene presentato un nuovo pattern $x$, la rete risponde producendo il patern salvato in memoria che più assomiglia ad $x$.\\

Hebb suggerisce variazioni sull'efficacia sinaptica proporzionali alla correlazione nell'attivazione tra un neurone pre e post sinaptico.
\begin{align}
	w_{ij} = \frac{1}{N} \sum_{\mu = 1}^p x_i^\mu x_j^\mu
\end{align}
dove $N$ è il numero di unità binarie con output $s_1, \dots, s_N$

Si consideri il seguente esempio con due pattern che la rete ha imparato:
\begin{align*}
	x^1 = (-1,-1,-1,+1) \\
	x^2 = (+1,+1,+1,+1)
\end{align*}
I pesi sono cosi calcolati:
\begin{align*}
	w_{ij} = \frac{1}{4} \sum_{\mu=1}^2 x_i^\mu x_j^\mu
\end{align*} 
Ad esempio:
\begin{align*}
	w_{12} = \frac{1}{4}(x^1_1 \cdot x^1_2 + x^2_1 \cdot x^2_2) = 
	\frac{1}{4}(-1 \cdot -1 + 1 \cdot 1) = \frac{1}{4} \cdot 2
\end{align*}
E quindi la matrice dei pesi ha la seguente forma:
\begin{align*}
	W = \frac{1}{4} \cdot
	\begin{bmatrix}
		2 & 2 & 2 & 0 \\
		2 & 2 & 2 & 0 \\
		2 & 2 & 2 & 0 \\
		0 & 0 & 0 & 2
	\end{bmatrix}
\end{align*}
Si ricorda che l'ouput dell'unità i è dato da:
\begin{align*}
	s_i = Sgn \left(\sum_j w_{ij} s_j \right)
\end{align*}
Ad esempio dato l'input $(-1,-1,-1,+1)$ la rete produce il seguente output:
\begin{align*}
	s_1 &= Sgn \left( \frac{1}{4} \cdot
	\begin{bmatrix}
		2 & 2 & 2 & 0 \\
		2 & 2 & 2 & 0 \\
		2 & 2 & 2 & 0 \\
		0 & 0 & 0 & 2
	\end{bmatrix} \cdot (-1, -1, -1, +1) \right) \\ 
	&= Sgn(-1.5, -1.5, -1.5, 0.5) = (-1,-1,-1,+1)
\end{align*}
Ed è una soluzione stabile in quanto corrisponde ad uno dei pattern memorizzati dalla rete, mentre il seguente esempio è una soluzione spuria:
\begin{align*}
	input^2 = (-1,-1,-1,-1)&\longrightarrow output^2 = (-1,-1,-1,-1) \tag{spuria}
\end{align*}


\newpage


\section{Modello di Hopfield: caso continuo} % (fold)
\label{sec:modello_di_hopfield_caso_continuo}
In questo modello i neuroni non sono più dispositivi binari con stati (0,1) o (-1,1), ma assumono un numero reale che identifica la quantità di corrente elettrica. La motivazione è creare un implementazione fisica di una rete di Hopfield; la resistenza elettrica è, infatti, continua.\\

In questo caso, l'output di un neurone $i$:
\begin{align}
    V_i = g_\beta(\mu_i) = g_\beta \left(\sum_{j} w_{ij} V_j + I_i \right) \qquad \text{oppure } \mu_i = g^{-1}_\beta(V_i) \label{eq:vi}
\end{align}
dove $g_\beta$ è la funzione di attivazione crescente, continua e non lineare. Le funzioni più utilizzate come $g$ sono la sigmoidea e la tangente iperbolica:
\begin{align*}
    \tanh_\beta \mu = \frac {e^{\beta\mu} - e^{-\beta\mu}} {e^\beta\mu + e^{-\beta\mu}} \quad\in ]-1,1[
    \qquad\qquad
    g_\beta(\mu) =\frac{1}{1 + e^{-2 \beta \mu}} \quad\in ]0,1[
\end{align*}

Il parametro $\beta$ indica la “stickiness” della funzione. Ad esempio con $\beta \rightarrow \infty$ la funzione diventa sempre più ripida fino a diventare lineare.\\

\begin{figure}[h!]
    \centering
    \begin{tikzpicture}[domain=-1:1,x=3cm,y=3cm,  every node/.style=very thick]
        \draw[very thin,color=gray!20] (-1,-1.2) grid (1,1.2);
        \draw[->] (-1,0) -- (1,0) node[right] {$x$};
        \draw[->] (0,-1.2) -- (0,1.2) node[above] {$f(x)$};
        \draw[color=blue] plot[id=tanh] function{tanh(1 * x)} node[right] {$\beta = 1$};
        \draw[color=red] plot[id=tanh] function{tanh(0.5 * x)} node[right] {$\beta < 1$};
        \draw[color=orange] plot[id=tanh] function{tanh(1.5 * x)} node[right] {$\beta > 1$};
        \draw[color=magenta] plot[id=tanh] function{tanh(100 * x)} node[above] {$\beta \rightarrow \infty$};
    \end{tikzpicture}
    \caption{La funzione tangente iperbolica $f(x) = \tanh(\beta \mu)$}\label{fig:stickiness}
\end{figure}

\newpage

L'utilizzo di valori continui permette la modalità di \emph{aggiornamento continuo}. In questo modo il tempo scorre in maniera continua. 

\begin{figure}[h!]
	\centering
	\subfigure[Caso discreto: $\Delta t$ costante]{
	\begin{tikzpicture}
		\draw[thick, color=blue] plot [mark=*,blue, tension=1]
		coordinates{(0, 0) (1, 1) (2, 2) ( 3, 1.5) (4, 2)};
		\node[] at (0, 0.4) {$t_1$};
		\node[] at (0.7, 0.2) {$\Delta t$};
		\node[] at (1, 1.4) {$t_2$};
	\end{tikzpicture}}
	\quad
	\subfigure[Caso continuo: $\Delta t \rightarrow 0$]{
	\begin{tikzpicture}
		\draw[thick, color=blue] plot [smooth, red, tension=1]
		coordinates{(0, 0) (2, 2) ( 3, 1.5) (4, 2)};
	\end{tikzpicture}}
	\caption{Traiettoria di una rete di Hopfield nel caso continuo e discreto.}
\end{figure}
Per descrivere completamente il comportamento del neurone si deve aggiungere alla \eqref{eq:vi} l'equazione che definisce il valore di attivazione del neurone stesso (vedi sezione 5.1); in questo caso, esso non è più la semplice somma algebrica degli ingressi (caso discreto) ma è una soluzione della seguente equazione differenziale:
\begin{align*}
	V_i + \tau_i \frac{d V_i}{dt} &= g_\beta \left(\sum_{j} w_{ij} V_j + I_i \right) \\
	\tau_i \frac{d V_i}{dt} &= - V_i + g_\beta(\mu_i) = - V_i + g_\beta \left(\sum_j w_{ji} V_j + I_i \right)
\end{align*}
dove $\tau_i$ è una costante ($\tau_i > 0$) e rappresenta la resistenza elettrica. Il sistema raggiunge la stabilità quando il vettore velocità del sistema si azzera $\Delta t = dV_i / dt= 0 \, \forall i$, ovvero quando l'uscita di ogni neurone $V_i$ è uguale a $g_\beta(\mu_i)$:
\begin{align*}
	V_i = g_\beta(\mu_i)
\end{align*}
In maniera del tutto equivalente è possibile esprimere l’equazione di stato non incentrando l’attenzione sulla variazione $V_i$ dello stato nel tempo, quanto sulla variazione $\mu_i$ dell’input netto nel tempo, pervenendo alla seguente equazione:
\begin{align}
	\mu_i + \tau_i \frac{d\mu_i}{dt} &= \sum_j w_{ij} V_j + I_i = \sum_j w_{ij} g_\beta (\mu_j) + I_i \\
	\tau_i \frac{d\mu_i}{dt} &= -\mu_i + \sum_j w_{ij} g_\beta (\mu_j) + I_i \label{eq:mu}
\end{align}

\newpage

La funzione energia nel modello continuo è simile a quella nel caso discreto ed è così definita:
\begin{align}
    E = - \frac{1}{2} \sum_i \sum_j w_{ij} V_i V_j + \sum_i \int_0^{V_i} g^{-1}_\beta (V) \, dV - \sum_i I_i V_i
\end{align}

Si dimostra ora il teorema di Hopfield nel caso continuo: 
\begin{thm}[Teorema di Hopfield - Caso Continuo]
	Se $W=W^T$ e $diag(W) = 0$ allora la funzione di energia $E$ è Lyapunoviana per il sistema e quindi $dE / dt \leq 0$, dove l'uguaglianza si ottiene quando il sistema ha raggiunto un punto stazionario.
\end{thm}

\begin{proof}[Dimostrazione:]
	È necessario dimostrare che $dE / dt \leq 0$ con uguaglianza quando un punto fisso è stato raggiunto. Si ricorda che solo $V_i$ dipende dal tempo.\\
	
	Nel calcolo della derivata $dE / dt$, al primo termine è applicata la regola del prodotto mentre per il secondo la regola della catena e il teorema fondamentale del calcolo integrale (vedi Appendice). In questo modo si ottiene:
	\begin{align*}
        \frac{dE}{dt} &= - \frac{1}{2} \sum_i \sum_j w_{ij} \frac{dV_i}{dt} V_j - \frac{1}{2} \sum_i \sum_j w_{ij} V_i \frac{dV_j}{dt} + \sum_i \underbrace{g_\beta^{-1}(V_i)}_\textrm{$= \mu_i$} \frac{dV_i}{dt} - \sum_i I_i \frac{d V_i}{dt} 
	\end{align*}
	Assumendo che $W$ è simmetrica le prime due sommatorie sono uguali e quindi:
	\begin{align*}
        \frac{dE}{dt} &=  - \sum_i \sum_j w_{ij} \frac{dV_i}{dt} V_j + \sum_i \mu_i \frac{dV_i}{dt} - \sum_i I_i \frac{d V_i}{dt} \\
		&= - \sum_i \frac{d V_i}{dt} \underbrace{\left(\sum_j w_{ij} V_j - \mu_i + I_i \right)}_\textrm{$ = \tau_i \frac{d \mu_i}{dt}$} \\
        &= - \sum_i \tau_i \frac{d V_i}{dt} \frac{d \mu_i}{dt}
	\end{align*}
	dove
	\begin{align*}
		\frac{d V_i}{dt} = \frac{d}{dt} \left(g_\beta (\mu_i) \right) = \frac{d \mu_i}{dt} \cdot g'_\beta(\mu_i)
	\end{align*}
	e quindi:
	\begin{align*}
        \frac{dE}{dt} = - \sum_i \tau_i g'_\beta(\mu_i) \left(\frac{d\mu_i}{dt} \right)^2 \leq 0
    \end{align*}
	
\newpage

    L'ultima disuguaglianza è vera perché $g_\beta$ è monotona crescente quindi la sua derivata $g'_\beta \geq 0$, $\tau_i > 0$ e il quadrato di un numero è sempre positivo. Dunque vale la seguente doppia implicazione:
    \begin{align*}
        \frac{dE}{dt} = 0 \Leftrightarrow \frac{d \mu_i}{dt} = 0
    \end{align*}
    cioè il valore dell'energia nel tempo rimane fisso se e solo se la rete ha raggiunto un punto di equilibrio, ovvero $\mu_i$.
\end{proof}

% section modello_di_hopfield_caso_continuo (end)
\section{Corrispondenza tra i due modelli} % (fold)
\label{sec:corrispondenza_tra_i_due_modelli}
Esiste una relazione stretta tra il modello continuo e quello discreto. Si noti che:
\begin{align*}
    V_i = g_\beta(\mu_i) = g_1(\beta \mu_i) = g(\beta \mu_i)
\end{align*}
Da cui si ricava che:
\begin{align*}
    \mu_i = \frac{1}{\beta} g^{-1} (V_i)
\end{align*}
Il secondo termine della funzione energia diventa quindi:
\begin{align*}
     \sum_i \int_0^{V_i} g^{-1}_\beta (V) \, dV = \frac{1}{\beta} \cdot \sum_i \int_0^{V_i} g^{-1} (V) \, dV 
\end{align*}
Ora per $\beta \rightarrow \infty$ il termine diventa trascurabile e la funzione $E$ risulta uguale a quella nel modello discreto.
\begin{align*}
    E &= - \frac{1}{2} \sum_i \sum_j w_{ij} V_i V_j + \underbrace{\frac{1}{\beta} \cdot \sum_i \int_0^{V_i} g^{-1} (V) \, dV}_\textrm{= 0 per $\beta \rightarrow \infty$}  - \sum_i I_i V_i \\
    &=  - \frac{1}{2} \sum_i \sum_j w_{ij} V_i V_j - \sum_{i=1}^n I_i V_i
\end{align*}
Intuitivamente per $\beta \rightarrow \infty$ la funzione diventa sempre più rigida fino a diventare lineare (vedi Figura~\ref{fig:stickiness}). Di conseguenza la funzione energia del caso continuo ora coincide con quella del modello discreto.
% section corrispondenza_tra_i_due_modelli (end)

% chapter reti_di_hopfield (end)



